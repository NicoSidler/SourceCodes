# ---------------------------
# 1. Setup and Data Loading
# ---------------------------

# Load necessary packages. Install any if not already installed.
if(!require(tidyverse)) install.packages("tidyverse", dependencies = TRUE)
if(!require(lme4)) install.packages("lme4", dependencies = TRUE)
if(!require(car)) install.packages("car", dependencies = TRUE)

library(tidyverse)
library(lme4)
library(car)

# Set the directory path where your data is located.
dir_path <- "C:/Users/Nico Sidler/OneDrive - Universitaet Bern/Desktop/SeminarPaper"

# Load the dataset (adjust the filename if needed)
data_path <- file.path(dir_path, "Seminar_Paper_data.csv")
data <- read.csv(data_path, stringsAsFactors = FALSE)

# View structure and summary of the data
str(data)
summary(data)


# ----------------------------------------
# 2. Data Cleaning and Preparation
# ----------------------------------------
# Convert variables to appropriate types based on the data description

# Categorical variables: participant_ID, accent, fluent, question, trait, gender, ethnicity, region, education
data$participant_ID <- as.factor(data$participant_ID)
data$accent <- factor(data$accent, levels = c("EE", "GNE", "LE", "MLE", "RP"))
data$fluent <- factor(data$fluent, levels = c("F", "D"))  # F = fluent, D = disfluencies
data$question <- factor(data$question, levels = c("non-expert", "expert"))
data$trait <- as.factor(data$trait)
data$gender <- as.factor(data$gender)
data$ethnicity <- as.factor(data$ethnicity)
data$region <- as.factor(data$region)
data$education <- factor(data$education, 
                         levels = c("GCSE", "Alevel", "FurtherEd", "Undergrad", "Postgrad"))

# Convert numeric variables: value (Likert scale ratings), professional_demeanour, presence_prejudice, imp_stand_lg, and age
data$value <- as.numeric(data$value)
data$professional_demeanour <- as.numeric(data$professional_demeanour)
data$presence_prejudice <- as.numeric(data$presence_prejudice)
data$imp_stand_lg <- as.numeric(data$imp_stand_lg)
data$age <- as.numeric(data$age)

# Check for missing values in each column
colSums(is.na(data))


# ------------------------------
# 3. Descriptive Analysis
# ------------------------------Likert-scale-----------------------------------------------------
# Install and load e1071 package if it's not already installed
if(!require(e1071)) install.packages("e1071", dependencies = TRUE)
library(e1071)

# Compute descriptive statistics for the entire Likert-scale ratings
descriptive_stats <- data %>% 
  summarise(
    Mean = mean(value, na.rm = TRUE),
    Median = median(value, na.rm = TRUE),
    SD = sd(value, na.rm = TRUE),
    Min = min(value, na.rm = TRUE),
    Max = max(value, na.rm = TRUE),
    Skewness = skewness(value, na.rm = TRUE),
    Kurtosis = kurtosis(value, na.rm = TRUE)
  )

print(descriptive_stats)

# Bar chart for Likert-scale
ggplot(data, aes(x = factor(value))) +
  geom_bar(fill = "chartreuse4", color = "black") +
  scale_x_discrete(limits = c("1", "2", "3", "4", "5", "6")) +
  labs(title = "Distribution of Likert Scale Ratings",
       x = "Likert Scale Value",
       y = "Number of Responses") +
  theme_minimal(base_size = 8)

#-------------------------------Likert-scale and traits-----------------------------------------

# Univariate Analysis: Frequency tables for categorical variables
table(data$accent)
prop.table(table(data$accent))  # Percentages

table(data$fluent)
table(data$question)
table(data$trait)
table(data$education)
table(data$gender)

# Summary of continuous variables by trait (Likert rating: value)

descriptive_stats <- data %>%
  group_by(trait) %>%
  summarise(
    Mean = mean(value, na.rm = TRUE),
    Median = median(value, na.rm = TRUE),
    SD = sd(value, na.rm = TRUE),
    Min = min(value, na.rm = TRUE),
    Max = max(value, na.rm = TRUE),
    Skewness = skewness(value, na.rm = TRUE),
    Kurtosis = kurtosis(value, na.rm = TRUE)
  )

print(descriptive_stats)

#Bar Chart for Likert scale by Trait
ggplot(data, aes(x = factor(value))) +
  geom_bar(fill = "chartreuse4", color = "black") +
  facet_wrap(~ trait) +
  scale_x_discrete(limits = c("1", "2", "3", "4", "5", "6")) +
  labs(title = "Distribution of Likert Scale Ratings by Trait",
       x = "Likert Scale Value",
       y = "Number of Responses") +
  theme_minimal(base_size = 8) +
  theme(axis.text.x = element_text(angle = 0, hjust = 1))


#--------------------------------------------Likert scale Fluency---------------------------------------------------------

# Summary of continuous variables by fluency (Likert rating: value)
descriptive_stats <- data %>%
  group_by(fluent) %>%
  summarise(
    Mean = mean(value, na.rm = TRUE),
    Median = median(value, na.rm = TRUE),
    SD = sd(value, na.rm = TRUE),
    Min = min(value, na.rm = TRUE),
    Max = max(value, na.rm = TRUE),
    Skewness = skewness(value, na.rm = TRUE),
    Kurtosis = kurtosis(value, na.rm = TRUE)
  )

print(descriptive_stats)


#Bar Chart for Likert scale by fluency
ggplot(data, aes(x = factor(value))) +
  geom_bar(fill = "chartreuse4", color = "black") +
  facet_wrap(~ fluent) +
  scale_x_discrete(limits = c("1", "2", "3", "4", "5", "6")) +
  labs(title = "Distribution of Likert Scale Ratings by Trait",
       x = "Likert Scale Value",
       y = "Number of Responses") +
  theme_minimal(base_size = 8) +
  theme(axis.text.x = element_text(angle = 0, hjust = 1))


# Compute descriptive statistics for Likert ratings by both fluency and trait
descriptive_stats <- data %>%
  group_by(fluent, trait) %>%
  summarise(
    Mean = mean(value, na.rm = TRUE),
    Median = median(value, na.rm = TRUE),
    SD = sd(value, na.rm = TRUE),
    Min = min(value, na.rm = TRUE),
    Max = max(value, na.rm = TRUE),
    Skewness = skewness(value, na.rm = TRUE),
    Kurtosis = kurtosis(value, na.rm = TRUE)
  ) %>%
  ungroup()

print(descriptive_stats)

#--------------------------------------------Likert scale question---------------------------------------------------------

# Summary of continuous variables by question (Likert rating: value)
descriptive_stats <- data %>%
  group_by(question) %>%
  summarise(
    Mean = mean(value, na.rm = TRUE),
    Median = median(value, na.rm = TRUE),
    SD = sd(value, na.rm = TRUE),
    Min = min(value, na.rm = TRUE),
    Max = max(value, na.rm = TRUE),
    Skewness = skewness(value, na.rm = TRUE),
    Kurtosis = kurtosis(value, na.rm = TRUE)
  )

print(descriptive_stats)


#Bar Chart for Likert scale by question
ggplot(data, aes(x = factor(value))) +
  geom_bar(fill = "chartreuse4", color = "black") +
  facet_wrap(~ question) +
  scale_x_discrete(limits = c("1", "2", "3", "4", "5", "6")) +
  labs(title = "Distribution of Likert Scale Ratings by Trait",
       x = "Likert Scale Value",
       y = "Number of Responses") +
  theme_minimal(base_size = 8) +
  theme(axis.text.x = element_text(angle = 0, hjust = 1))


# Compute descriptive statistics for Likert ratings by both fluency and trait
descriptive_stats <- data %>%
  group_by(question, trait) %>%
  summarise(
    Mean = mean(value, na.rm = TRUE),
    Median = median(value, na.rm = TRUE),
    SD = sd(value, na.rm = TRUE),
    Min = min(value, na.rm = TRUE),
    Max = max(value, na.rm = TRUE),
    Skewness = skewness(value, na.rm = TRUE),
    Kurtosis = kurtosis(value, na.rm = TRUE)
  ) %>%
  ungroup()

print(descriptive_stats)

#--------------------------------------------Likert scale accent---------------------------------------------------------

# Summary of continuous variables by accent (Likert rating: value)
descriptive_stats <- data %>%
  group_by(accent) %>%
  summarise(
    Mean = mean(value, na.rm = TRUE),
    Median = median(value, na.rm = TRUE),
    SD = sd(value, na.rm = TRUE),
    Min = min(value, na.rm = TRUE),
    Max = max(value, na.rm = TRUE),
    Skewness = skewness(value, na.rm = TRUE),
    Kurtosis = kurtosis(value, na.rm = TRUE)
  )

print(descriptive_stats)


#Bar Chart for Likert scale by question
ggplot(data, aes(x = factor(value))) +
  geom_bar(fill = "chartreuse4", color = "black") +
  facet_wrap(~ accent) +
  scale_x_discrete(limits = c("1", "2", "3", "4", "5", "6")) +
  labs(title = "Distribution of Likert Scale Ratings by Trait",
       x = "Likert Scale Value",
       y = "Number of Responses") +
  theme_minimal(base_size = 8) +
  theme(axis.text.x = element_text(angle = 0, hjust = 1))


# Compute descriptive statistics for Likert ratings by both fluency and trait
descriptive_stats <- data %>%
  group_by(accent, trait) %>%
  summarise(
    Mean = mean(value, na.rm = TRUE),
    Median = median(value, na.rm = TRUE),
    SD = sd(value, na.rm = TRUE),
    Min = min(value, na.rm = TRUE),
    Max = max(value, na.rm = TRUE),
    Skewness = skewness(value, na.rm = TRUE),
    Kurtosis = kurtosis(value, na.rm = TRUE)
  ) %>%
  ungroup()

print(descriptive_stats, n = 40)

#--------------------------------------------Likert scale gender---------------------------------------------------------

# Summary of continuous variables by gender (Likert rating: value)
descriptive_stats <- data %>%
  group_by(gender) %>%
  summarise(
    Mean = mean(value, na.rm = TRUE),
    Median = median(value, na.rm = TRUE),
    SD = sd(value, na.rm = TRUE),
    Min = min(value, na.rm = TRUE),
    Max = max(value, na.rm = TRUE),
    Skewness = skewness(value, na.rm = TRUE),
    Kurtosis = kurtosis(value, na.rm = TRUE)
  )

print(descriptive_stats)


#Bar Chart for Likert scale by gender
ggplot(data, aes(x = factor(value))) +
  geom_bar(fill = "chartreuse4", color = "black") +
  facet_wrap(~ gender) +
  scale_x_discrete(limits = c("1", "2", "3", "4", "5", "6")) +
  labs(title = "Distribution of Likert Scale Ratings by Trait",
       x = "Likert Scale Value",
       y = "Number of Responses") +
  theme_minimal(base_size = 8) +
  theme(axis.text.x = element_text(angle = 0, hjust = 1))


# Compute descriptive statistics for Likert ratings by both gender and trait
descriptive_stats <- data %>%
  group_by(gender, trait) %>%
  summarise(
    Mean = mean(value, na.rm = TRUE),
    Median = median(value, na.rm = TRUE),
    SD = sd(value, na.rm = TRUE),
    Min = min(value, na.rm = TRUE),
    Max = max(value, na.rm = TRUE),
    Skewness = skewness(value, na.rm = TRUE),
    Kurtosis = kurtosis(value, na.rm = TRUE)
  ) %>%
  ungroup()

print(descriptive_stats, n = 32)

#--------------------------------------------Likert scale education---------------------------------------------------------

# Summary of continuous variables by education (Likert rating: value)
descriptive_stats <- data %>%
  group_by(education) %>%
  summarise(
    Mean = mean(value, na.rm = TRUE),
    Median = median(value, na.rm = TRUE),
    SD = sd(value, na.rm = TRUE),
    Min = min(value, na.rm = TRUE),
    Max = max(value, na.rm = TRUE),
    Skewness = skewness(value, na.rm = TRUE),
    Kurtosis = kurtosis(value, na.rm = TRUE)
  )

print(descriptive_stats)


#Bar Chart for Likert scale by education
ggplot(data, aes(x = factor(value))) +
  geom_bar(fill = "chartreuse4", color = "black") +
  facet_wrap(~ education) +
  scale_x_discrete(limits = c("1", "2", "3", "4", "5", "6")) +
  labs(title = "Distribution of Likert Scale Ratings by Trait",
       x = "Likert Scale Value",
       y = "Number of Responses") +
  theme_minimal(base_size = 8) +
  theme(axis.text.x = element_text(angle = 0, hjust = 1))


# Compute descriptive statistics for Likert ratings by both education and trait
descriptive_stats <- data %>%
  group_by(education, trait) %>%
  summarise(
    Mean = mean(value, na.rm = TRUE),
    Median = median(value, na.rm = TRUE),
    SD = sd(value, na.rm = TRUE),
    Min = min(value, na.rm = TRUE),
    Max = max(value, na.rm = TRUE),
    Skewness = skewness(value, na.rm = TRUE),
    Kurtosis = kurtosis(value, na.rm = TRUE)
  ) %>%
  ungroup()

print(descriptive_stats, n = 40)

----------------------------------------Likert-scale age---------------------------------------------------

  #------------------------------------------------------------------
# Step 1. Create Age Groups (10-Year Intervals up to age 74)
#------------------------------------------------------------------

# Here we assume that the minimum age is, for example, 18.
# We want to create intervals that cover [18,28), [28,38), ..., [68,75) so that age 74 falls in the final interval.
data <- data %>%
  mutate(age_group = cut(age,
                         breaks = c(seq(floor(min(age, na.rm = TRUE)), 74, by = 10), 75),
                         right = FALSE,         # left-closed, right-open intervals: [x, x+10)
                         include.lowest = TRUE))  # include the lowest age

#------------------------------------------------------------------
# Step 2. Compute Descriptive Statistics for Likert Evaluations by Age Group
#------------------------------------------------------------------

age_evaluation_stats <- data %>%
  group_by(age_group) %>%
  summarise(
    Count    = n(),
    Mean     = mean(value, na.rm = TRUE),
    Median   = median(value, na.rm = TRUE),
    SD       = sd(value, na.rm = TRUE),
    Min      = min(value, na.rm = TRUE),
    Max      = max(value, na.rm = TRUE),
    Skewness = skewness(value, na.rm = TRUE),
    Kurtosis = kurtosis(value, na.rm = TRUE)
  ) %>%
  ungroup()

print(age_evaluation_stats)


# Bivariate Analysis: Cross-tabulations and comparisons
# For example, cross-tabulate accent and question type
table_accent_question <- table(data$accent, data$question)
print(table_accent_question)

# Boxplot to compare ratings by accent and question type, faceted by fluent condition
ggplot(data, aes(x = accent, y = value, fill = question)) +
  geom_boxplot() +
  facet_wrap(~ fluent) +
  labs(title = "Ratings by Accent and Question Type, Separated by Fluent Condition",
       x = "Accent", y = "Rating Value") +
  theme_minimal()

# Boxplot to compare ratings by accent and question type, faceted by fluent condition
ggplot(data, aes(x = trait, y = value, fill = question)) +
  geom_boxplot() +
  facet_wrap(~ fluent) +
  scale_x_discrete(labels = c(
    "articulate" = "a",
    "confident" = "c",
    "do.well.interviews" = "dwi",
    "knowledgeable" = "k",
    "likely.to.succeed" = "lts",
    "organised" = "o",
    "pleasant" = "p",
    "professional" = "pro"
  )) +
  labs(title = "Ratings by Trait and Question Type, Separated by Fluent Condition",
       x = "Trait", y = "Rating Value") +
  theme_minimal()

#Boxplots across all dependet variables
ggplot(data, aes(x = trait, y = value, fill = question)) +
  geom_boxplot(outlier.colour = "red", outlier.shape = 16, outlier.size = 0.2) +
  facet_grid(accent ~ fluent) +
  scale_x_discrete(labels = c(
    "articulate" = "a",
    "confident" = "c",
    "do.well.interviews" = "dwi",
    "knowledgeable" = "k",
    "likely.to.succeed" = "lts",
    "organised" = "o",
    "pleasant" = "p",
    "professional" = "pro"
  )) +
  labs(title = "Relationship of Trait, Accent, Fluency & Question to Value",
       x = "Trait",
       y = "Rating Value") +
  theme_minimal(base_size = 8)



#Boxplots across all dependet variables and not outliers

ggplot(data, aes(x = trait, y = value, fill = question)) +
  geom_boxplot(outlier.shape = NA) +
  facet_grid(accent ~ fluent) +
  scale_x_discrete(labels = c(
    "articulate" = "a",
    "confident" = "c",
    "do.well.interviews" = "dwi",
    "knowledgeable" = "k",
    "likely.to.succeed" = "lts",
    "organised" = "o",
    "pleasant" = "p",
    "professional" = "pro"
  )) +
  labs(title = "Relationship of Trait, Accent, Fluency & Question to Value",
       x = "Trait",
       y = "Rating Value") +
  theme_minimal(base_size = 8)


# ----------------------------------
# 4. Inferential Statistical Analysis
# ----------------------------------

# Given that each respondent provides multiple ratings, a mixed-effects model is appropriate.
# Here, the dependent variable is "value" and predictors include accent, fluent, and question.
# We include a random intercept for participant_ID to account for repeated measures.
mixed_model <- lmer(value ~ accent * fluent * question + (1 | participant_ID), 
                    data = data, REML = FALSE)
summary(mixed_model)

# Check model assumptions: residual plots and Q-Q plot
par(mfrow = c(1, 2))
plot(resid(mixed_model), main = "Residuals Plot", ylab = "Residuals", xlab = "Index")
qqnorm(resid(mixed_model), main = "Normal Q-Q Plot of Residuals")
qqline(resid(mixed_model))
par(mfrow = c(1, 1))

# Alternatively, if you prefer a simple regression model ignoring repeated measures:
lm_model <- lm(value ~ accent * fluent * question, data = data)
summary(lm_model)
# Diagnostic plots for the linear model
par(mfrow = c(2, 2))
plot(lm_model)
par(mfrow = c(1, 1))

# A more comprehensive regression model including attitudinal measures:
full_model <- lm(value ~ accent * fluent * question + 
                   professional_demeanour + presence_prejudice + imp_stand_lg,
                 data = data)
summary(full_model)
# Model diagnostics for the full model
par(mfrow = c(2, 2))
plot(full_model)
par(mfrow = c(1, 1))


# ----------------------------
# 5. Additional and Subgroup Analyses
# ----------------------------

# Exploratory: Relationship between attitudinal measures and ratings
# Create a correlation matrix for continuous attitudinal measures and rating (value)
attitudinal_vars <- data %>% 
  select(value, professional_demeanour, presence_prejudice, imp_stand_lg, age)
cor_matrix <- cor(attitudinal_vars, use = "complete.obs")
print(cor_matrix)

# Visualizing correlations using a pairs plot
pairs(attitudinal_vars, main = "Scatterplot Matrix of Attitudinal Measures and Ratings")

# Subgroup Analysis: For example, examining rating differences across genders
ggplot(data, aes(x = gender, y = value, fill = gender)) +
  geom_boxplot() +
  labs(title = "Distribution of Ratings by Gender",
       x = "Gender", y = "Rating Value") +
  theme_minimal()


# ---------------------------
# 6. Reporting and Interpretation
# ---------------------------
# At this stage, review the outputs from:
#   - Descriptive statistics and plots to check for distribution patterns and outliers.
#   - Mixed-effects and linear regression models to assess main effects and interactions.
#   - Diagnostic plots to ensure model assumptions are met.
#
# Based on the significant results and observed patterns, you can then draw conclusions
# regarding how variables (e.g., accent, fluent condition, legal expertise of the question) influence
# the perceived ratings. Additional subgroup or sensitivity analyses can help further explore
# nuanced differences in the data.
#
# Finally, document the analysis steps, report key findings, and discuss implications in your seminar paper.
