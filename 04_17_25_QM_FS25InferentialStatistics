# 0) Install & load required packages
pkgs <- c("dplyr", "tidyr", "ggplot2")
invisible(lapply(pkgs, function(p) {
  if (!requireNamespace(p, quietly = TRUE)) {
    install.packages(p, dependencies = TRUE)
  }
  library(p, character.only = TRUE)
}))

# 1) Compute each participant’s overall mean rating in Disfluent (D) vs. Fluent (F)
means_df <- data %>%
  group_by(participant_ID, fluent) %>%
  summarise(mean_rating = mean(value, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(names_from = fluent, values_from = mean_rating) %>%
  filter(!is.na(D) & !is.na(F))

# 2) Create difference scores (F - D)
diffs <- means_df$F - means_df$D

# 3) Assumption check: Normality of difference scores

# 3a) Histogram + density
hist(diffs,
     main   = "Histogram of Difference Scores (F - D)",
     xlab   = "Difference in Mean Rating",
     breaks = 30,
     col    = "lightgray",
     border = "black")
lines(density(diffs), col = "blue", lwd = 2)

# 3b) QQ-plot
qqnorm(diffs)
qqline(diffs, col = "red", lwd = 2)

# 3c) Shapiro–Wilk test not to be done because of large sample size!
shapiro_result <- shapiro.test(diffs)
print(shapiro_result)   # p > .05 suggests normality

# 4) Assumption check: Outliers in difference scores

# 4a) Boxplot to visually flag outliers
boxplot(diffs,
        main = "Boxplot of Difference Scores (F - D)",
        ylab = "Difference in Mean Rating")

# 4b) Identify numeric outliers via 1.5 × IQR rule
Q1      <- quantile(diffs, 0.25)
Q3      <- quantile(diffs, 0.75)
IQR_val <- IQR(diffs)
outliers <- diffs[ diffs < (Q1 - 1.5 * IQR_val) |
                     diffs > (Q3 + 1.5 * IQR_val) ]
print(outliers)         # any extreme cases worth noting

# 5) Run paired-samples t-test
tt <- t.test(means_df$D, means_df$F, paired = TRUE)

# 6) Compute Cohen's d for paired samples
cohen_d <- mean(diffs) / sd(diffs)

# 7) Summarize results
t_test_summary <- data.frame(
  n        = nrow(means_df),
  t_stat   = unname(tt$statistic),
  df       = unname(tt$parameter),
  p_value  = tt$p.value,
  cohens_d = cohen_d
)

# 8) Print summary table
print(t_test_summary)

#------- test with outliers----------------

# 0) Install & load required packages
pkgs <- c("dplyr", "tidyr", "ggplot2")
invisible(lapply(pkgs, function(p) {
  if (!requireNamespace(p, quietly = TRUE)) {
    install.packages(p, dependencies = TRUE)
  }
  library(p, character.only = TRUE)
}))

# 1) Compute each participant’s overall mean rating in Disfluent (D) vs. Fluent (F)
means_df <- data %>%
  group_by(participant_ID, fluent) %>%
  summarise(mean_rating = mean(value, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(names_from = fluent, values_from = mean_rating) %>%
  filter(!is.na(D) & !is.na(F))

# 2) Create difference scores (F - D)
diffs <- means_df$F - means_df$D

# 3) Assumption check: Normality of difference scores

# 3a) Histogram + density
hist(diffs,
     main   = "Histogram of Difference Scores (F - D)",
     xlab   = "Difference in Mean Rating",
     breaks = 30,
     col    = "lightgray",
     border = "black")
lines(density(diffs), col = "blue", lwd = 2)

# 3b) QQ-plot
qqnorm(diffs)
qqline(diffs, col = "red", lwd = 2)

# 3c) Shapiro–Wilk test (often overly sensitive with large n)
shapiro_result <- shapiro.test(diffs)
print(shapiro_result)

# 4) Assumption check: Outliers in difference scores

# 4a) Boxplot to visually flag outliers
boxplot(diffs,
        main = "Boxplot of Difference Scores (F - D)",
        ylab = "Difference in Mean Rating")

# 4b) Identify numeric outliers via 1.5 × IQR rule
Q1         <- quantile(diffs, 0.25)
Q3         <- quantile(diffs, 0.75)
IQR_val    <- IQR(diffs)
lower_fence <- Q1 - 1.5 * IQR_val
upper_fence <- Q3 + 1.5 * IQR_val

outlier_idx <- which(diffs < lower_fence | diffs > upper_fence)
outlier_values <- diffs[outlier_idx]
print(outlier_idx)       # row indices of outliers in means_df
print(outlier_values)    # the outlier difference scores

# 5) Remove outliers and rerun analyses

# 5a) Filter out the outlier rows
filtered_means_df <- means_df[-outlier_idx, ]
filtered_diffs   <- filtered_means_df$F - filtered_means_df$D

# 5b) Paired-samples t-test on filtered data
tt_filtered <- t.test(filtered_means_df$D,
                      filtered_means_df$F,
                      paired = TRUE)

# 5c) Compute Cohen’s d on the filtered difference scores
cohen_d_filtered <- mean(filtered_diffs) / sd(filtered_diffs)

# 5d) Summarize filtered results
t_test_summary_filtered <- data.frame(
  n        = nrow(filtered_means_df),
  t_stat   = unname(tt_filtered$statistic),
  df       = unname(tt_filtered$parameter),
  p_value  = tt_filtered$p.value,
  cohens_d = cohen_d_filtered
)

# 5e) Print the filtered summary table
print(t_test_summary_filtered)


#------------------- Fluency: Paired t-test and Cohen's D (F/D on each trait) not good option, rather do ANOVA-----------------

# 0) Install & load packages
pkgs <- c("dplyr", "tidyr")
invisible(lapply(pkgs, function(p) {
  if (!require(p, character.only = TRUE)) {
    install.packages(p, dependencies = TRUE)
    library(p, character.only = TRUE)
  }
}))

# 1) Loop over traits
trait_results <- lapply(sort(unique(data$trait)), function(tr) {
  d <- filter(data, trait == tr)
  
  # Prepare paired data
  paired <- d %>%
    group_by(participant_ID, fluent) %>%
    summarise(mean_val = mean(value, na.rm = TRUE), .groups = "drop") %>%
    pivot_wider(names_from = fluent, values_from = mean_val) %>%
    filter(!is.na(F) & !is.na(D))
  
  # Paired t-test
  t_test <- t.test(paired$D, paired$F, paired = TRUE)
  p_ttest <- t_test$p.value
  
  # Cohen's d for paired data
  diffs <- paired$D - paired$F
  cohen_d <- if (length(diffs) > 1) mean(diffs) / sd(diffs) else NA_real_
  
  # Return results
  data.frame(
    trait           = tr,
    F_mean          = round(mean(paired$F, na.rm = TRUE), 3),
    D_mean          = round(mean(paired$D, na.rm = TRUE), 3),
    diff_D_minus_F  = round(mean(diffs, na.rm = TRUE), 3),
    ttest_p         = round(p_ttest, 3),
    cohens_d        = round(cohen_d, 3),
    stringsAsFactors = FALSE
  )
})

# 2) Combine and view
trait_summary <- do.call(rbind, trait_results)
print(trait_summary)


#------------ Assumptions for t-test for each trait----------------------
# Assumption checks for the “articulate” trait

# 1) Prepare paired data for trait == "articulate"
paired_articulate <- data %>%
  filter(trait == "articulate") %>%
  group_by(participant_ID, fluent) %>%
  summarise(mean_val = mean(value, na.rm = TRUE), .groups = "drop") %>%
  pivot_wider(names_from = fluent, values_from = mean_val) %>%
  filter(!is.na(F) & !is.na(D))

# 2) Compute difference scores (D – F)
diffs_articulate <- paired_articulate$D - paired_articulate$F

# 3) Normality of difference scores

# 3a) Histogram + density
hist(diffs_articulate,
     main   = "Histogram of Difference Scores (D - F)\nTrait: articulate",
     xlab   = "Difference in Mean Rating (D - F)",
     breaks = 30,
     col    = "lightgray",
     border = "black")
lines(density(diffs_articulate), col = "blue", lwd = 2)

# 3b) QQ-plot
qqnorm(diffs_articulate,
       main = "QQ-Plot of Difference Scores (D - F)\nTrait: articulate")
qqline(diffs_articulate, col = "red", lwd = 2)

# 4) Outliers in difference scores

# 4a) Boxplot
boxplot(diffs_articulate,
        main = "Boxplot of Difference Scores (D - F)\nTrait: articulate",
        ylab = "Difference in Mean Rating (D - F)")

# 4b) 1.5 × IQR rule
Q1         <- quantile(diffs_articulate, 0.25)
Q3         <- quantile(diffs_articulate, 0.75)
IQR_val    <- IQR(diffs_articulate)
lower_fence <- Q1 - 1.5 * IQR_val
upper_fence <- Q3 + 1.5 * IQR_val

outliers_articulate <- diffs_articulate[
  diffs_articulate < lower_fence |
  diffs_articulate > upper_fence
]
print(outliers_articulate)  # any extreme difference scores


#------------------------------------------------------------------------ANOVA and Bonferroni (also Fluency, but more complex model)

# 0) Install & load required packages
pkgs <- c("dplyr", "tidyr", "afex", "emmeans", "car", "ggplot2")
invisible(lapply(pkgs, function(p) {
  if (!requireNamespace(p, quietly = TRUE)) {
    install.packages(p, dependencies = TRUE)
  }
  library(p, character.only = TRUE)
}))

# 1) Compute each participant’s mean rating per trait × fluency
summary_data <- data %>%
  group_by(participant_ID, trait, fluent) %>%
  summarise(
    mean_rating = mean(value, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    participant_ID = factor(participant_ID),
    trait          = factor(trait),
    fluent         = factor(fluent, levels = c("D", "F"))  # Ensure "D" (Disfluent) and "F" (Fluent) order
  )

# 2) Run the 2 (Fluency: D vs. F) × 8 (Trait) repeated-measures ANOVA
anova_model <- aov_ez(
  id      = "participant_ID",    # subject identifier
  dv      = "mean_rating",       # dependent variable
  data    = summary_data,
  within  = c("fluent", "trait"),
  type    = 3                    # Type III sums of squares
)

# 3) View the omnibus ANOVA table
print(anova_model)

# 4) Check assumptions

## 4a) Normality of residuals (visual check only, no Shapiro-Wilk because n > 5000)
residuals_anova <- residuals(anova_model$lm)

# Histogram of residuals
hist(residuals_anova,
     main = "Histogram of Residuals",
     xlab = "Residuals",
     breaks = 30,
     col = "lightgray",
     border = "black")
lines(density(residuals_anova), col = "blue", lwd = 2)

# Correct QQ plot (manual method, fixing the 'sample' naming issue)
# Create theoretical quantiles and residual values
qq_data <- qqnorm(residuals_anova, plot.it = FALSE)

# Carefully convert to a clean dataframe
qq_df <- data.frame(
  theoretical = as.numeric(qq_data$x),
  residual_value = as.numeric(qq_data$y)
)

# Plot QQ plot with ggplot2
ggplot(qq_df, aes(x = theoretical, y = residual_value)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(title = "QQ Plot of Residuals",
       x = "Theoretical Quantiles",
       y = "Sample Quantiles") +
  theme_minimal()



# 5) Post‑hoc paired comparisons (Fluent vs. Disfluent) within each trait
emm <- emmeans(anova_model, ~ fluent | trait)
posthoc <- contrast(emm, method = "pairwise", adjust = "bonferroni")

# 6) Display the post‑hoc results
print(posthoc)



#-----------------------------ANOVA and Bonferroni for Accent----------------------

# Required packages
pkgs <- c("dplyr", "afex", "emmeans")
invisible(lapply(pkgs, function(p) {
  if (!require(p, character.only = TRUE)) {
    install.packages(p, dependencies = TRUE)
    library(p, character.only = TRUE)
  }
}))

# Run repeated-measures ANOVA
anova_result <- afex::aov_ez(
  id = "participant_ID",
  dv = "value",
  data = data,
  within = "accent",  # 5-level IV
  fun_aggregate = mean,
  return = "afex_aov"
)

# See ANOVA table
print(afex::nice(anova_result))

# Post-hoc comparisons (Tukey-style pairwise comparisons)
em <- emmeans::emmeans(anova_result, ~accent)
contrast_results <- emmeans::contrast(em, method = "pairwise", adjust = "bonferroni")
summary(contrast_results)


#--EE-RP comparison (they are significant in the ANOVA)-----------------

# ─── 1. Load & install required packages ─────────────────────────────────────
pkgs <- c("dplyr", "afex", "emmeans", "broom", "tidyr")
invisible(lapply(pkgs, function(p) {
  if (!requireNamespace(p, quietly = TRUE)) install.packages(p, dependencies = TRUE)
  library(p, character.only = TRUE)
}))

# ─── 2. Helper: extract the 'accent' p-value from the afex table ─────────────
get_accent_p <- function(aov_tab) {
  p_col <- intersect(c("Pr(>F)", "p.value"), colnames(aov_tab))
  if (length(p_col) == 0) return(NA_real_)
  idx  <- grepl("^accent$", aov_tab$Effect, ignore.case = TRUE)
  vals <- aov_tab[[p_col]][idx]
  if (length(vals) > 0) vals[1] else NA_real_
}

# ─── 3. Loop over traits & build EE vs RP summary ─────────────────────────────
ee_rp_results <- lapply(sort(unique(data$trait)), function(tr) {
  d <- data %>% filter(trait == tr)

  # skip if missing one of the two accents
  if (!all(c("EE", "RP") %in% unique(d$accent))) {
    warning(sprintf("Trait '%s' missing EE or RP—skipping.", tr))
    return(NULL)
  }

  # 3.1 Repeated‑measures ANOVA
  m <- afex::aov_ez(
    id            = "participant_ID",
    dv            = "value",
    data          = d,
    within        = "accent",
    fun_aggregate = mean,
    return        = "afex_aov"
  )

  # 3.2 Extract the ANOVA p-value
  aov_tab <- afex::nice(m)
  anova_p <- get_accent_p(aov_tab)

  # 3.3 Tukey‑adjusted pairwise contrasts
  em    <- emmeans::emmeans(m, ~accent)
  ph    <- emmeans::contrast(em, method = "pairwise", adjust = "tukey")
  ph_df <- broom::tidy(ph)

  # dynamically detect the p‑value column and copy into adj.p.value
  possible_p <- names(ph_df)[grepl("p", tolower(names(ph_df)))]
  # keep only numeric p‑like columns
  possible_p <- possible_p[sapply(ph_df[possible_p], is.numeric)]
  if (length(possible_p) == 0) {
    warning(sprintf("Trait '%s': no p‑value column in pairwise results—setting adj.p.value = NA", tr))
    ph_df$adj.p.value <- NA_real_
  } else {
    # prefer the exact 'p.value' if present
    sel <- if ("p.value" %in% possible_p) "p.value" else possible_p[1]
    ph_df$adj.p.value <- ph_df[[sel]]
  }

  # keep only EE vs RP contrasts, flip if needed, and add metadata
  out <- ph_df %>%
    filter(contrast %in% c("EE - RP", "RP - EE")) %>%
    mutate(
      estimate = ifelse(contrast == "RP - EE", -estimate, estimate),
      contrast = "EE - RP",
      trait    = tr,
      anova_p  = anova_p
    )

  # 3.4 Compute paired Cohen's d for EE vs RP
  paired <- d %>%
    filter(accent %in% c("EE", "RP")) %>%
    group_by(participant_ID, accent) %>%
    summarise(mean_val = mean(value, na.rm = TRUE), .groups = "drop") %>%
    tidyr::pivot_wider(names_from = accent, values_from = mean_val) %>%
    filter(!is.na(EE), !is.na(RP))

  diffs <- paired$EE - paired$RP
  out$cohens_d <- if (length(diffs) > 1) round(mean(diffs) / sd(diffs), 3) else NA_real_

  out
})

# ─── 4. Combine & display ────────────────────────────────────────────────────
ee_rp_summary <- do.call(rbind, ee_rp_results)

ee_rp_summary %>%
  select(trait, estimate, adj.p.value, cohens_d, anova_p) %>%
  print()

#--------------------Accent other possibilities (Tukey's HSD)------------------------
# 0) Install & load packages
pkgs <- c("dplyr", "afex", "emmeans")
invisible(lapply(pkgs, function(p) {
  if (!require(p, character.only = TRUE)) {
    install.packages(p, dependencies = TRUE)
    library(p, character.only = TRUE)
  }
}))

# 1) Run repeated-measures ANOVA
anova_result <- afex::aov_ez(
  id = "participant_ID",    # participant identifier
  dv = "value",             # dependent variable
  data = data,              # your dataset
  within = "accent",        # within-subject factor
  fun_aggregate = mean,     # average across multiple trials per participant
  return = "afex_aov"
)

# 2) View ANOVA table
print(afex::nice(anova_result))

# 3) Post-hoc pairwise comparisons: Tukey's HSD
em <- emmeans::emmeans(anova_result, ~accent)
tukey_results <- emmeans::contrast(em, method = "tukey")
summary(tukey_results)

